{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHRF1fXDlvhyvZZdFurr5J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LbjCdFcfgo40","executionInfo":{"status":"ok","timestamp":1707035013812,"user_tz":-330,"elapsed":180101,"user":{"displayName":"Ranul Malaka","userId":"04876110509657867750"}},"outputId":"2e73cfd0-aeba-4ee1-966c-9d3c95f806d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import time\n","import matplotlib.pyplot as plt\n","import cv2\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import shutil\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","import time\n","from tqdm import tqdm"],"metadata":{"id":"sYX49YOfhOIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2  # Split data into training and validation sets\n",")\n","\n","image_height=224\n","image_width=224\n","batch_size=50\n","\n","'''train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/autism (1)/train',\n","    target_size=(image_width, image_height),\n","    batch_size=batch_size,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/autism (1)/valid',\n","    target_size=(image_width, image_height),\n","    batch_size=batch_size,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","'''\n","'''# Specify the path to the parent directory\n","data_directory = '/content/drive/MyDrive/autism (1)/dataset'\n","'''\n","root_directory = '/content/drive/MyDrive/autism (1)/dataset'\n","\n","train_dir = os.path.join(root_directory,'train')\n","validation_dir = os.path.join(root_directory,'valid')\n","test_dir = os.path.join(root_directory,'test')\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2  # Split data into training and validation sets\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    root_directory,\n","    target_size=(image_width, image_height),\n","    batch_size=batch_size,\n","    class_mode='binary',\n","    subset='training',\n","    shuffle=True  # Shuffle the data for better training\n",")\n","\n","\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(image_width, image_height),\n","    batch_size=batch_size,\n","    class_mode='binary',\n","    subset='validation',\n","    shuffle=False  # No need to shuffle validation data\n",")\n","\n","print(train_generator.samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IMraQkFhCba","executionInfo":{"status":"ok","timestamp":1707037437209,"user_tz":-330,"elapsed":384,"user":{"displayName":"Ranul Malaka","userId":"04876110509657867750"}},"outputId":"d635cebf-6b91-40fc-9420-2e1994b011f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2341 images belonging to 3 classes.\n","Found 40 images belonging to 2 classes.\n","2341\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(image_width, image_height, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.summary()\n"],"metadata":{"id":"GocPhXgKjSaA","executionInfo":{"status":"ok","timestamp":1707037713253,"user_tz":-330,"elapsed":433,"user":{"displayName":"Ranul Malaka","userId":"04876110509657867750"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"048feebe-cd8e-44a8-d572-2b9a4b3d0066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 222, 222, 32)      896       \n","                                                                 \n"," max_pooling2d_6 (MaxPoolin  (None, 111, 111, 32)      0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 109, 109, 64)      18496     \n","                                                                 \n"," max_pooling2d_7 (MaxPoolin  (None, 54, 54, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 52, 52, 128)       73856     \n","                                                                 \n"," max_pooling2d_8 (MaxPoolin  (None, 26, 26, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_2 (Flatten)         (None, 86528)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 128)               11075712  \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 11169089 (42.61 MB)\n","Trainable params: 11169089 (42.61 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"PhHnTHbbjWtL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YB9VRUELt7U5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs=500\n","ask_epoch=10\n","ask=LR_ASK(model, epochs,  ask_epoch)\n","#rlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n","#callbacks=[rlronp, ask]\n","callbacks=[ask]\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // batch_size\n",")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkTb1fhpjdC7","executionInfo":{"status":"ok","timestamp":1707038229486,"user_tz":-330,"elapsed":507077,"user":{"displayName":"Ranul Malaka","userId":"04876110509657867750"}},"outputId":"a4a2b876-1bfd-4306-a7d5-9f2605ce6675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["73\n","Epoch 1/100\n","47/73 [==================>...........] - ETA: 4:27 - loss: 0.2585 - accuracy: 0.8633"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7300 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 496s 7s/step - loss: 0.2585 - accuracy: 0.8633 - val_loss: 40.5538 - val_accuracy: 0.5000\n"]}]}]}